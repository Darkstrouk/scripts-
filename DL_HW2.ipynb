{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "max_cell_id": 35,
    "colab": {
      "name": "Boro_hw2.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 1,
        "id": "kr9vAeEQlRVG"
      },
      "source": [
        "# Домашнее задание 2. Классификация изображений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 3,
        "id": "BxX49gLclRVJ"
      },
      "source": [
        "В этом задании потребуется обучить классификатор изображений. Будем работать сдатасетом, название которого раскрывать не будем. Можете посмотреть самостоятельно на картинки, которые в есть датасете. В нём 200 классов и около 5 тысяч картинок на каждый класс. Классы пронумерованы, как нетрудно догадаться, от 0 до 199. Скачать датасет можно вот [тут](https://yadi.sk/d/BNR41Vu3y0c7qA).\n",
        "\n",
        "Структура датасета простая -- есть директории train/ и val/, в которых лежат обучающие и валидационные данные. В train/ и val/ лежат директориии, соответствующие классам изображений, в которых лежат, собственно, сами изображения.\n",
        " \n",
        "__Задание__. Необходимо выполнить любое из двух заданий\n",
        "\n",
        "1) Добейтесь accuracy **на валидации не менее 0.44**. В этом задании **запрещено** пользоваться предобученными моделями и ресайзом картинок. \n",
        "\n",
        "2) Добейтесь accuracy **на валидации не менее 0.84**. В этом задании делать ресайз и использовать претрейн можно. \n",
        "\n",
        "Напишите краткий отчёт о проделанных экспериментах. Что сработало и что не сработало? Почему вы решили, сделать так, а не иначе? Обязательно указывайте ссылки на чужой код, если вы его используете. Обязательно ссылайтесь на статьи / блогпосты / вопросы на stackoverflow / видосы от ютуберов-машинлернеров / курсы / подсказки от Дяди Васи и прочие дополнительные материалы, если вы их используете. \n",
        "\n",
        "Ваш код обязательно должен проходить все `assert`'ы ниже.\n",
        "\n",
        "Необходимо написать функции `train_one_epoch`, `train` и `predict` по шаблонам ниже (во многом повторяют примеры с семинаров).Обратите особое внимание на функцию `predict`: она должна возвращать список лоссов по всем объектам даталоадера, список предсказанных классов для каждого объекта из даталоалера и список настоящих классов для каждого объекта в даталоадере (и именно в таком порядке).\n",
        "\n",
        "__Использовать внешние данные для обучения строго запрещено в обоих заданиях. Также запрещено обучаться на валидационной выборке__.\n",
        "\n",
        "\n",
        "__Критерии оценки__: Оценка вычисляется по простой формуле: `min(10, 10 * Ваша accuracy / 0.44)` для первого задания и `min(10, 10 * (Ваша accuracy - 0.5) / 0.34)` для второго. Оценка округляется до десятых по арифметическим правилам. Если вы выполнили оба задания, то берется максимум из двух оценок.\n",
        "\n",
        "__Бонус__. Вы получаете 5 бонусных баллов если справляетесь с обоими заданиями на 10 баллов (итого 15 баллов). В противном случае выставляется максимальная из двух оценок и ваш бонус равен нулю.\n",
        "\n",
        "__Советы и указания__:\n",
        " - Наверняка вам потребуется много гуглить о классификации и о том, как заставить её работать. Это нормально, все гуглят. Но не забывайте, что нужно быть готовым за скатанный код отвечать :)\n",
        " - Используйте аугментации. Для этого пользуйтесь модулем `torchvision.transforms` или библиотекой [albumentations](https://github.com/albumentations-team/albumentations)\n",
        " - Можно обучать с нуля или файнтюнить (в зависимости от задания) модели из `torchvision`.\n",
        " - Рекомендуем написать вам сначала класс-датасет (или воспользоваться классом `ImageFolder`), который возвращает картинки и соответствующие им классы, а затем функции для трейна по шаблонам ниже. Однако делать это мы не заставляем. Если вам так неудобно, то можете писать код в удобном стиле. Однако учтите, что чрезмерное изменение нижеперечисленных шаблонов увеличит количество вопросов к вашему коду и повысит вероятность вызова на защиту :)\n",
        " - Валидируйте. Трекайте ошибки как можно раньше, чтобы не тратить время впустую.\n",
        " - Чтобы быстро отладить код, пробуйте обучаться на маленькой части датасета (скажем, 5-10 картинок просто чтобы убедиться что код запускается). Когда вы поняли, что смогли всё отдебажить, переходите обучению по всему датасету\n",
        " - На каждый запуск делайте ровно одно изменение в модели/аугментации/оптимайзере, чтобы понять, что и как влияет на результат.\n",
        " - Фиксируйте random seed.\n",
        " - Начинайте с простых моделей и постепенно переходите к сложным. Обучение лёгких моделей экономит много времени.\n",
        " - Ставьте расписание на learning rate. Уменьшайте его, когда лосс на валидации перестаёт убывать.\n",
        " - Советуем использовать GPU. Если у вас его нет, используйте google colab. Если вам неудобно его использовать на постоянной основе, напишите и отладьте весь код локально на CPU, а затем запустите уже написанный ноутбук в колабе. Авторское решение задания достигает требуемой точности в колабе за 15 минут обучения.\n",
        " \n",
        "Good luck & have fun! :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 4,
        "id": "LKcSNj4tlRVK"
      },
      "source": [
        "\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import os, copy, numpy as np\n",
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "\n",
        "\n",
        "import sys\n",
        "\n",
        "%matplotlib inline\n",
        "# You may add any imports you need"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RytEDW0ylRVN"
      },
      "source": [
        "### Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3V8gh_tuWkd"
      },
      "source": [
        "#!unzip /content/drive/MyDrive/dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 5,
        "id": "QEdDQtHdlRVO"
      },
      "source": [
        "data_transforms = { 'train': transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4802, 0.4481, 0.3975), (1, 1, 1)), ]),\n",
        "                    'val'  : transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4802, 0.4481, 0.3975), (1, 1, 1)), ]) }\n",
        "\n",
        "data_dir = '/content/dataset/dataset'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64, shuffle=True, num_workers=2)\n",
        "              for x in ['train', 'val']}\n",
        "\n",
        "train_dataset = dataloaders['train']\n",
        "val_dataset = dataloaders['val']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RlSlmyjlRVP"
      },
      "source": [
        "### Вспомогательные функции, реализация модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK6QMD-rs5-s"
      },
      "source": [
        "def train_one_epoch(model, train_dataloader, optimizer, criterion, return_losses=True, device=\"cuda:0\"):\n",
        "    model.to(device).train()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    all_losses = []\n",
        "    total_predictions = np.array([])\n",
        "    total_labels = np.array([])\n",
        "    \n",
        "    with tqdm(total=len(train_dataloader), file=sys.stdout) as prbar:\n",
        "        for images, labels in train_dataloader:\n",
        "            # Move Batch to GPU\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            predicted = model(images)\n",
        "            loss = criterion(predicted, labels)\n",
        "\n",
        "           \n",
        "\n",
        "            # Update weights\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            accuracy = (predicted.argmax(1) == labels).float().mean()\n",
        "            prbar.set_description(f\"Loss: {round(loss.item(), 4)} \"\n",
        "                                  f\"Accuracy: {round(accuracy.item() * 100, 4)}\")\n",
        "            prbar.update(1)\n",
        "\n",
        "            # Update descirption for tqdm\n",
        "            accuracy = (predicted.argmax(1) == labels).float().mean()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n",
        "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
        "            num_batches += 1\n",
        "            all_losses.append(loss.detach().item())\n",
        "        \n",
        "    metrics = {\"loss\": total_loss / num_batches}\n",
        "    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n",
        "    \n",
        "    if return_losses:\n",
        "        return metrics, all_losses\n",
        "    else:\n",
        "        return metrics\n",
        "\n",
        "\n",
        "\n",
        "def validate(model, data_loader, criterion, device=\"cuda:0\"):\n",
        "    model.eval()\n",
        "    # YOUR CODE\n",
        "    # PREDICT FOR EVERY ELEMENT OF THE VAL DATALOADER AND RETURN CORRESPONDING LISTS\n",
        "    total_loss = np.array([])\n",
        "    num_batches = 0\n",
        "    total_predictions = np.array([])\n",
        "    total_labels = np.array([]) \n",
        "    m = []\n",
        "    \n",
        "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
        "        for images, labels in data_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            predicted = model(images)\n",
        "\n",
        "            loss = criterion(predicted, labels)\n",
        "            accuracy = (predicted.argmax(1) == labels).float().mean()\n",
        "            \n",
        "            prbar.set_description(f\"Loss: {round(loss.item(), 4)} \"\n",
        "                                  f\"Accuracy: {round(accuracy.item() * 100, 4)}\")\n",
        "            prbar.update(1)\n",
        "\n",
        "            #print('loss', loss.item())\n",
        "            total_loss = np.append(total_loss, loss.item())\n",
        "            #print('total_loss', total_loss)\n",
        "            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n",
        "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
        "            num_batches += 1\n",
        "        \n",
        "    metrics = {\"losses\": total_loss}\n",
        "    metrics.update({\"predicted_classes\": total_predictions})\n",
        "    metrics.update({\"true_classes\":  total_labels})\n",
        "    m.append(total_loss)\n",
        "    m.append(total_predictions)\n",
        "    m.append(total_labels)\n",
        "    return m"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYbkyH8ws9zf"
      },
      "source": [
        "def train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", epochs=5, scheduler=None):\n",
        "    model.to(device)\n",
        "    all_train_losses = []\n",
        "    epoch_train_losses = []\n",
        "    epoch_eval_losses = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Train step\n",
        "        print(f\"Train Epoch: {epoch}\")\n",
        "        train_metrics, one_epoch_train_losses = train_one_epoch(model = model,\n",
        "                                                                train_dataloader = train_dataloader,\n",
        "                                                                optimizer=optimizer,\n",
        "                                                                criterion=criterion,\n",
        "                                                                return_losses=True,\n",
        "                                                                device=device)\n",
        "        \n",
        "        # Save Train losses\n",
        "        all_train_losses.extend(one_epoch_train_losses)\n",
        "        epoch_train_losses.append(train_metrics[\"loss\"])\n",
        "        \n",
        "        # Eval step\n",
        "        print(f\"Validation Epoch: {epoch}\")\n",
        "        with torch.no_grad():\n",
        "            validation_metrics = validate(model=model, data_loader=val_dataloader, criterion=criterion, device=\"cuda:0\")\n",
        "            \n",
        "        # Save eval losses\n",
        "        epoch_eval_losses.append(validation_metrics[0])\n",
        "        #print(f\"Epoch: {epoch}, metrics: {validation_metrics}\")\n",
        "        \n",
        "        #metrics = {\"loss\": total_loss / num_batches}\n",
        "        accuracy = ({\"accuracy\": (validation_metrics[1] == validation_metrics[2]).mean()})\n",
        "\n",
        "        print('Точность', accuracy)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxR3gfcilRVW"
      },
      "source": [
        "### Обучение модели, запуски экспериментов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxCvHqDitSPc"
      },
      "source": [
        "from torchvision.models import resnet18\n",
        "model = models.resnet18(pretrained=False)\n",
        "\n",
        "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 200)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "model = torch.nn.DataParallel(model, device_ids=[0])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGVnmBfXti_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "584fe022-6ed1-48e6-c914-3eedaca7a9cc"
      },
      "source": [
        "train(model, train_dataset, val_dataset, criterion, optimizer, device, 5, scheduler)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0\n",
            "Loss: 3.7744 Accuracy: 12.5: 100%|██████████| 1563/1563 [02:47<00:00,  9.31it/s]\n",
            "Validation Epoch: 0\n",
            "Loss: 3.5076 Accuracy: 18.75: 100%|██████████| 157/157 [00:07<00:00, 21.27it/s]\n",
            "Точность {'accuracy': 0.1658}\n",
            "Train Epoch: 1\n",
            "Loss: 2.9477 Accuracy: 31.25: 100%|██████████| 1563/1563 [02:47<00:00,  9.34it/s]\n",
            "Validation Epoch: 1\n",
            "Loss: 3.7412 Accuracy: 18.75: 100%|██████████| 157/157 [00:07<00:00, 21.84it/s]\n",
            "Точность {'accuracy': 0.2351}\n",
            "Train Epoch: 2\n",
            "Loss: 3.1324 Accuracy: 25.0: 100%|██████████| 1563/1563 [02:46<00:00,  9.36it/s]\n",
            "Validation Epoch: 2\n",
            "Loss: 3.6485 Accuracy: 25.0: 100%|██████████| 157/157 [00:07<00:00, 21.75it/s]\n",
            "Точность {'accuracy': 0.293}\n",
            "Train Epoch: 3\n",
            "Loss: 2.6217 Accuracy: 37.5: 100%|██████████| 1563/1563 [02:47<00:00,  9.36it/s]\n",
            "Validation Epoch: 3\n",
            "Loss: 2.1522 Accuracy: 37.5: 100%|██████████| 157/157 [00:07<00:00, 20.89it/s]\n",
            "Точность {'accuracy': 0.3213}\n",
            "Train Epoch: 4\n",
            "Loss: 2.0806 Accuracy: 46.875: 100%|██████████| 1563/1563 [02:47<00:00,  9.32it/s]\n",
            "Validation Epoch: 4\n",
            "Loss: 3.0127 Accuracy: 25.0: 100%|██████████| 157/157 [00:07<00:00, 21.16it/s]\n",
            "Точность {'accuracy': 0.3299}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx9Rdw-gPYNz"
      },
      "source": [
        "Сделаю еще 3 эпохи"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdbE4h41PU4k",
        "outputId": "e90326eb-1f65-4cf4-ec59-7549d873ddbf"
      },
      "source": [
        "train(model, train_dataset, val_dataset, criterion, optimizer, device, 3, scheduler)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0\n",
            "Loss: 2.0827 Accuracy: 53.125: 100%|██████████| 1563/1563 [02:48<00:00,  9.26it/s]\n",
            "Validation Epoch: 0\n",
            "Loss: 3.5157 Accuracy: 18.75: 100%|██████████| 157/157 [00:07<00:00, 20.62it/s]\n",
            "Точность {'accuracy': 0.3511}\n",
            "Train Epoch: 1\n",
            "Loss: 1.2563 Accuracy: 68.75: 100%|██████████| 1563/1563 [02:49<00:00,  9.20it/s]\n",
            "Validation Epoch: 1\n",
            "Loss: 3.8886 Accuracy: 37.5: 100%|██████████| 157/157 [00:07<00:00, 20.86it/s]\n",
            "Точность {'accuracy': 0.3392}\n",
            "Train Epoch: 2\n",
            "Loss: 0.6701 Accuracy: 78.125: 100%|██████████| 1563/1563 [02:49<00:00,  9.22it/s]\n",
            "Validation Epoch: 2\n",
            "Loss: 2.8344 Accuracy: 25.0: 100%|██████████| 157/157 [00:07<00:00, 20.76it/s]\n",
            "Точность {'accuracy': 0.3333}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImVW8_EXlRVZ"
      },
      "source": [
        "### Проверка полученной accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": 10,
        "id": "B_LB2jn6lRVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e6af67-013d-45db-e179-8a4aa89ab57f"
      },
      "source": [
        "with torch.no_grad():\n",
        "  validation_metrics = validate(model=model, data_loader=val_dataset, criterion=criterion, device=\"cuda:0\")\n",
        "\n",
        "all_losses, predicted_labels, true_labels = validation_metrics[0], validation_metrics[1], validation_metrics[2]\n",
        "assert len(predicted_labels) == len(true_labels)\n",
        "accuracy = accuracy_score(predicted_labels, true_labels)\n",
        "print(\"tests passed\")\n",
        "\n",
        "print('Точность:', accuracy)\n",
        "print(\"Оценка за это задание составит {} баллов\".format(min(10, 10 * (accuracy)) / 0.4))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.2835 Accuracy: 25.0: 100%|██████████| 157/157 [00:07<00:00, 20.98it/s]\n",
            "tests passed\n",
            "Точность: 0.3333\n",
            "Оценка за это задание составит 8.3325 баллов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": 15,
        "id": "pT8vfPSolRVb"
      },
      "source": [
        "### Отчёт об экспериментах \n",
        "\n",
        "\n",
        "Мой подход - сначала оптимизировал предобученную модель до 0.76, потом на полученной архитектуре и без ресайза сделать pretrained = False.\n",
        "\n",
        "Что помогло:\n",
        "\n",
        "- смена последних слоев: добавил AdaptiveAvgPool2d(1) и поменял последний слой, чтобы resnet смог выдавать 200 классов. AdaptiveAvgPool2d показал наилучшие результаты\n",
        "\n",
        "- Нормализация картинок дала значительный прирост\n",
        "\n",
        "Что не помогло:\n",
        "\n",
        "- Другие модели: VGG16, EfficientNet работали хуже, несмотря на то, что в статьях было указано обратное\n",
        "\n",
        "- другие оптимизаторы: Adam и RMSprop давали результаты хуже, чем обычный SGD\n",
        "\n",
        "- Аугментации не приводили к значительному приросту точности, оптимизации архитектуры более влиятельный подход\n",
        "\n",
        "- Кроп не давал никаких результатов, хоть и нам всё подсказывали его юзать\n",
        "\n"
      ]
    }
  ]
}